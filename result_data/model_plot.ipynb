{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import networks.resnet32_gda as res\n",
    "from bayes_layer import NoiseLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoiseLayerSTD(model_name, ratio=None, task_num=10):\n",
    "    cnt = 0\n",
    "    sample_num = []\n",
    "    model = res.resnet32(100)\n",
    "    \n",
    "    rand_std = []\n",
    "    for (_, layer) in model.named_children():\n",
    "        if isinstance(layer, NoiseLayer) == False:\n",
    "            continue\n",
    "        out_features = layer.rho.shape[0]\n",
    "        \n",
    "        sample_num.append(out_features)\n",
    "#         std_arr = np.zeros((sample_num[cnt], task_num+1))\n",
    "        std_arr = np.zeros((sample_num[cnt], task_num))\n",
    "        rand_idx = np.arange(out_features)\n",
    "        np.random.shuffle(rand_idx)\n",
    "        rand_idx = np.sort(rand_idx[:sample_num[cnt]])\n",
    "        \n",
    "        std_init = math.sqrt(out_features*ratio)\n",
    "        std_arr[:,0] = np.ones(sample_num[cnt]) * std_init\n",
    "        for t in range(task_num):\n",
    "            model.load_state_dict(torch.load(model_name%t))\n",
    "            \n",
    "            std = np.log(1+np.exp(layer.rho.data.cpu().numpy())).reshape((out_features))\n",
    "            std = np.sort(std[rand_idx])\n",
    "#             std_arr[:,t+1] = std[rand_idx]\n",
    "#             std_arr[:,t+1] = std\n",
    "#             std_arr[:,t] = std[rand_idx]\n",
    "            std_arr[:,t] = std\n",
    "            \n",
    "        reg_arr = (std_init/std_arr)**2\n",
    "        rand_std.append(std_arr)\n",
    "#         rand_std.append(reg_arr)\n",
    "        cnt += 1\n",
    "        \n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    for l in range(cnt):\n",
    "        \n",
    "        for i in range(sample_num[l]):\n",
    "#             plt.plot(np.arange(task_num+1), rand_std[l][i], linestyle = '-')\n",
    "            plt.plot(np.arange(task_num), rand_std[l][i], linestyle = '-')\n",
    "\n",
    "        fontsize = 20\n",
    "#         plt.xticks(np.arange(task_num+1),fontsize = fontsize)\n",
    "        plt.xticks(np.arange(task_num),fontsize = fontsize)\n",
    "        plt.yticks(fontsize = 15)\n",
    "\n",
    "        plt.xlabel('Task', fontsize = fontsize)\n",
    "        if l==0:\n",
    "            plt.ylabel('STD',fontsize = fontsize)\n",
    "#             plt.ylabel('Strength',fontsize = fontsize)\n",
    "        \n",
    "#         plt.ylim(0,100)\n",
    "        \n",
    "        plt.title('Layer %d'%(l+1), fontsize = fontsize)\n",
    "        plt.tight_layout()\n",
    "\n",
    "#     plt.savefig('figure/histogram_layer.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FC_weight_bias(model_name, task_num=10):\n",
    "    cnt = 0\n",
    "    model = res.resnet32(100)\n",
    "    for (_, layer) in model.named_children():\n",
    "        if isinstance(layer, nn.Linear) == False:\n",
    "            continue\n",
    "        bias_arr = np.zeros((100, task_num))\n",
    "        \n",
    "        for t in range(task_num):\n",
    "            model.load_state_dict(torch.load(model_name%t))\n",
    "            bias = layer.bias.data.cpu().numpy()\n",
    "            bias_arr[:,t] = np.abs(bias)\n",
    "            \n",
    "        cnt += 1\n",
    "        \n",
    "    plt.figure(figsize=(10,8))\n",
    "    for i in range(100):\n",
    "        plt.plot(np.arange(task_num), bias_arr[i], linestyle = '-')\n",
    "\n",
    "    fontsize = 20\n",
    "    plt.xticks(np.arange(task_num),fontsize = fontsize)\n",
    "\n",
    "    plt.xlabel('Task', fontsize = fontsize)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(sns.color_palette(\"husl\", 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '../models/trained_model/GDA_CIFAR100_gda_0_memsz_2000_alpha_0.0001_ratio_0.50000000_beta_1e-05_lr_0.1_batch_64_epoch_100_task_%d.pt'\n",
    "NoiseLayerSTD(name, ratio=0.5, task_num=10)\n",
    "name = '../models/trained_model/GDA_CIFAR100_gda_0_memsz_2000_alpha_0.0001_ratio_0.00390625_beta_1e-05_lr_0.1_batch_64_epoch_100_task_%d.pt'\n",
    "NoiseLayerSTD(name, ratio=0.00390625, task_num=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '../models/trained_model/GDA_CIFAR100_gda_0_memsz_2000_alpha_0.0001_ratio_0.50000000_beta_1e-05_lr_0.1_batch_64_epoch_100_task_%d.pt'\n",
    "FC_weight_bias(name, task_num=10)\n",
    "name = '../models/trained_model/GDA_CIFAR100_gda_0_memsz_2000_alpha_0.0001_ratio_0.00390625_beta_1e-05_lr_0.1_batch_64_epoch_100_task_%d.pt'\n",
    "FC_weight_bias(name, task_num=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
